{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JTLpZTyObtHI"
   },
   "source": [
    "\n",
    "# VGG16 CNN in TensorFlow\n",
    "\n",
    "### In this project we are going to:\n",
    "<br/>\n",
    "#### 1. Prepare the environment (e.g., importing the required libraries)\n",
    "#### 2. Load and preprocess a dataset to train on \n",
    "#### 3. Implement a fully functioning ConvNet using TensorFlow\n",
    "#### 4. Train the implemented model on the prepared dataset\n",
    "#### 5. Analyze the results\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r0nu8p77btHK"
   },
   "source": [
    "## **1 - Preparing the environment**\n",
    "\n",
    "As usual, we will start by loading in the packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZWhhmFrsbtHL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\deeplearning\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "from tensorflow.python.training import basic_session_run_hooks\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oier10NbbtHQ"
   },
   "source": [
    "## **2 - Load and preprocess the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "EKltkRHAbtHR",
    "outputId": "a674173c-4ddf-4230-f919-8a5ec9df4626"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-f11ec4649917>:2: load_dataset (from tensorflow.contrib.learn.python.learn.datasets) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data.\n",
      "WARNING:tensorflow:From C:\\deeplearning\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\__init__.py:80: load_mnist (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\deeplearning\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:300: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\deeplearning\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\deeplearning\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\deeplearning\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\deeplearning\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# Loading the data (signs)\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images  # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "eval_data = mnist.test.images  # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eUA9gbbqbtHb"
   },
   "source": [
    "As a reminder, the MNIST dataset is a collection of images representing numbers from 0 to 9.\n",
    "\n",
    "<img src=\"images/mnist.jpg\" style=\"width:800px;height:800px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "Yk7j6PY1btHd",
    "outputId": "b8f52b7a-8cdb-4858-e651-d285ec8c803b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of a picture\n",
    "train_data.shape\n",
    "index = 7\n",
    "plt.imshow(train_data[index].reshape(28, 28))\n",
    "print (\"y = \" + str(np.squeeze(train_labels[index])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "6fkw58X3btHk",
    "outputId": "a0f6c66b-43fa-4ddb-9335-e848f53aabe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 55000\n",
      "number of evaluation examples = 10000\n",
      "X_train shape: (55000, 784)\n",
      "Y_train shape: (55000,)\n",
      "X_test shape: (10000, 784)\n",
      "Y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# get some statistic from the dataset\n",
    "print (\"number of training examples = \" + str(train_data.shape[0]))\n",
    "print (\"number of evaluation examples = \" + str(eval_data.shape[0]))\n",
    "print (\"X_train shape: \" + str(train_data.shape))\n",
    "print (\"Y_train shape: \" + str(train_labels.shape))\n",
    "print (\"X_test shape: \" + str(eval_data.shape))\n",
    "print (\"Y_test shape: \" + str(eval_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HqwKc3dfbtH0"
   },
   "source": [
    "\n",
    "Let's see one of these 3x3 filters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZHe7jJcvbtH2"
   },
   "source": [
    "## **4 - Implementing the full VGG-16 CNN network:**\n",
    "<br/>\n",
    "<img src=\"images/vgg16.png\" style=\"width:1000px;height:150px;\">\n",
    "<br/>\n",
    "In TensorFlow, there are built-in functions that carry out the convolution steps.\n",
    "\n",
    "- **`tf.layers.conv2d(input, num_filters, filter_size, padding='same', activation=tf.nn.relu)`:** given an input and a group of filters, this function convolves filters on the input.\n",
    "\n",
    "- **`tf.layers.max_ppoling2d(input, pool_size, strides, padding='same')`:** given an input, this function uses a window of size `pool_size` and strides to carry out max pooling over each window.\n",
    "\n",
    "- **`tf.contrib.layers.flatten(P)`**: given an input P, this function flattens each example into a 1D vector it while maintaining the batch-size. It returns a flattened tensor with shape [batch_size, k].\n",
    "\n",
    "- **`tf.layers.dense(input, units, activation=tf.nn.relu)`:** given a the flattened input, it returns the output computed using a fully connected layer. The `units' determine the number of neuron in the FC layer.\n",
    "\n",
    "In the last function above (`tf.layers.dense`), the fully connected layer automatically initializes weights in the graph and keeps on training them as you train the model. Hence, we do not need to initialize those weights.\n",
    "\n",
    "Now we implement the `cnn_model_fn(features, labels, model)` function below to build the following model: \n",
    "`2 x CONV2D -> RELU -> MAXPOOL -> 2 x CONV2D -> RELU -> MAXPOOL -> 3 x CONV2D -> RELU -> MAXPOOL -> 3 x CONV2D -> RELU -> MAXPOOL -> 3 x CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FC1 -> FC2 -> FC3 -> output`\n",
    "\n",
    "In detail, we will use the following parameters for all the steps:\n",
    "     - Conv2D: A 3 by 3 filter size with stride 1, padding is \"same\" with relu activation function\n",
    "     - Max pool: A 2 by 2 filter size with stride 2, padding is \"same\"\n",
    "     \n",
    "Here is the text version of the network in the original paper:\n",
    "<br/>\n",
    "<img src=\"images/vgg-text.png\" style=\"width:400px;height:400px;\">\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ejuJCL1WbtH3"
   },
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    # Input Layer\n",
    "    input_height, input_width = 28, 28\n",
    "    input_channels = 1\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, input_height, input_width, input_channels])\n",
    "\n",
    "    # Convolutional Layer #1 and Pooling Layer #1\n",
    "    conv1_1 = tf.layers.conv2d(inputs=input_layer, filters=64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    conv1_2 = tf.layers.conv2d(inputs=conv1_1, filters=64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1_2, pool_size=[2, 2], strides=2, padding=\"same\")\n",
    "    \n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2_1 = tf.layers.conv2d(inputs=pool1, filters=128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    conv2_2 = tf.layers.conv2d(inputs=conv2_1, filters=128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2_2, pool_size=[2, 2], strides=2, padding=\"same\")\n",
    "\n",
    "    # Convolutional Layer #3 and Pooling Layer #3\n",
    "    conv3_1 = tf.layers.conv2d(inputs=pool2, filters=256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    conv3_2 = tf.layers.conv2d(inputs=conv3_1, filters=256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    # VGG16\n",
    "    conv3_3 = tf.layers.conv2d(inputs=conv3_2, filters=256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3_2, pool_size=[2, 2], strides=2, padding=\"same\")\n",
    "\n",
    "    # Convolutional Layer #4 and Pooling Layer #4\n",
    "    conv4_1 = tf.layers.conv2d(inputs=pool3, filters=512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    conv4_2 = tf.layers.conv2d(inputs=conv4_1, filters=512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    # VGG16\n",
    "    conv4_3 = tf.layers.conv2d(inputs=conv4_2, filters=512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    pool4 = tf.layers.max_pooling2d(inputs=conv4_2, pool_size=[2, 2], strides=2, padding=\"same\")\n",
    "\n",
    "    # Convolutional Layer #5 and Pooling Layer #5\n",
    "    conv5_1 = tf.layers.conv2d(inputs=pool4, filters=512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    conv5_2 = tf.layers.conv2d(inputs=conv5_1, filters=512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    # VGG16\n",
    "    conv5_3 = tf.layers.conv2d(inputs=conv5_2, filters=512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    pool5 = tf.layers.max_pooling2d(inputs=conv5_2, pool_size=[2, 2], strides=2, padding=\"same\")\n",
    "\n",
    "    # FC Layers\n",
    "    pool5_flat = tf.contrib.layers.flatten(pool5)\n",
    "    FC1 = tf.layers.dense(inputs=pool5_flat, units=4096, activation=tf.nn.relu)\n",
    "    FC2 = tf.layers.dense(inputs=FC1, units=4096, activation=tf.nn.relu)\n",
    "    FC3 = tf.layers.dense(inputs=FC2, units=1000, activation=tf.nn.relu)\n",
    "\n",
    "    \"\"\"the training argument takes a boolean specifying whether or not the model is currently \n",
    "    being run in training mode; dropout will only be performed if training is true. here, \n",
    "    we check if the mode passed to our model function cnn_model_fn is train mode. \"\"\"\n",
    "    dropout = tf.layers.dropout(inputs=FC3, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    # Logits Layer or the output layer. which will return the raw values for our predictions.\n",
    "    # Like FC layer, logits layer is another dense layer. We leave the activation function empty \n",
    "    # so we can apply the softmax\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "    \n",
    "    # Then we make predictions based on raw output\n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        # the predicted class for each example - a vlaue from 0-9\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        # to calculate the probablities for each target class we use the softmax\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    \n",
    "    # so now our predictions are compiled in a dict object in python and using that we return an estimator object\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    \n",
    "    '''Calculate Loss (for both TRAIN and EVAL modes): computes the softmax entropy loss. \n",
    "    This function both computes the softmax activation function as well as the resulting loss.'''\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Options (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(labels=labels,\n",
    "                                        predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                      loss=loss,\n",
    "                                      eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I44w9-RFbtId"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4151
    },
    "colab_type": "code",
    "id": "2Qjl_kD_btIf",
    "outputId": "111393be-c417-4f32-8b72-d246232e22a2",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/mnist_vgg16_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000232E5C167B8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/mnist_vgg16_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3025668, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 92 into /tmp/mnist_vgg16_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.152071\n",
      "INFO:tensorflow:loss = 2.3023496, step = 101 (657.589 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 181 into /tmp/mnist_vgg16_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.144675\n",
      "INFO:tensorflow:loss = 2.301877, step = 201 (691.260 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 262 into /tmp/mnist_vgg16_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.133213\n",
      "INFO:tensorflow:loss = 2.301074, step = 301 (750.674 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 346 into /tmp/mnist_vgg16_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.150485\n",
      "INFO:tensorflow:loss = 2.3019896, step = 401 (664.511 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 438 into /tmp/mnist_vgg16_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.152841\n",
      "INFO:tensorflow:loss = 2.3020597, step = 501 (654.369 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 531 into /tmp/mnist_vgg16_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.153647\n",
      "INFO:tensorflow:loss = 2.3029475, step = 601 (650.749 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 619 into /tmp/mnist_vgg16_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.0124071\n",
      "INFO:tensorflow:loss = 2.3019922, step = 701 (8059.954 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 706 into /tmp/mnist_vgg16_model\\model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 798 into /tmp/mnist_vgg16_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.152971\n",
      "INFO:tensorflow:loss = 2.3010852, step = 801 (653.626 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 893 into /tmp/mnist_vgg16_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.15805\n",
      "INFO:tensorflow:loss = 2.3018575, step = 901 (632.710 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 989 into /tmp/mnist_vgg16_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.159099\n",
      "INFO:tensorflow:loss = 2.301896, step = 1001 (628.538 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1085 into /tmp/mnist_vgg16_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.159376\n",
      "INFO:tensorflow:loss = 2.302244, step = 1101 (627.449 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1181 into /tmp/mnist_vgg16_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.159266\n",
      "INFO:tensorflow:loss = 2.3016899, step = 1201 (627.938 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1277 into /tmp/mnist_vgg16_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.158629\n",
      "INFO:tensorflow:loss = 2.301869, step = 1301 (630.383 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1372 into /tmp/mnist_vgg16_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.158832\n",
      "INFO:tensorflow:loss = 2.3018944, step = 1401 (629.742 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1468 into /tmp/mnist_vgg16_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.15922\n",
      "INFO:tensorflow:loss = 2.300294, step = 1501 (627.938 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1564 into /tmp/mnist_vgg16_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.156752\n",
      "INFO:tensorflow:loss = 2.3009367, step = 1601 (637.950 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1656 into /tmp/mnist_vgg16_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.149037\n",
      "INFO:tensorflow:loss = 2.2998667, step = 1701 (670.962 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1745 into /tmp/mnist_vgg16_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.147334\n",
      "INFO:tensorflow:loss = 2.29883, step = 1801 (678.724 sec)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn,\n",
    "                                          model_dir=\"/tmp/mnist_vgg16_model\")\n",
    "\n",
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": train_data},\n",
    "                                                    y=train_labels,\n",
    "                                                    batch_size=100,\n",
    "                                                    num_epochs=100,\n",
    "                                                    shuffle=True)\n",
    "mnist_classifier.train(input_fn=train_input_fn,\n",
    "                       hooks=None,\n",
    "                       steps=None,\n",
    "                       max_steps=None,\n",
    "                       saving_listeners=None\n",
    "                      )\n",
    "\n",
    "# Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": eval_data},\n",
    "                                                   y=eval_labels,\n",
    "                                                   num_epochs=1,\n",
    "                                                   shuffle=False)\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zvk1n0UEbtIl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "VGG16-MNIST-try.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
